#include <iostream>
#include <jni.h>


#include <queue>
#include <opencv2/opencv.hpp>
#include <opencv2/imgproc.hpp>
#include <thread>

extern "C" {
#include <libavutil/avutil.h>
#include <libswscale/swscale.h>
#include <libavcodec/avcodec.h>
#include <libavformat/avformat.h>
#include <libswresample/swresample.h>
#include <libavutil/time.h>
}

#include <android/log.h>

#define LOGE(FORMAT, ...) __android_log_print(ANDROID_LOG_ERROR,"LC",FORMAT,##__VA_ARGS__);

using namespace cv;
using namespace std;

AVFormatContext *ic = NULL;
char *outUrl = "rtmp://172.20.10.2:1935/live/hls";
bool isRunning = true;
bool isExit[3] = {0};

mutex packs_mux;
queue<AVPacket *> packs;


SwsContext *vsc = NULL;
AVFrame *yuv_frame = NULL;
AVCodecContext *vc = NULL;
AVStream *vs = NULL;


SwrContext *asc = nullptr;
AVFrame *pcm_frame = NULL;
AVCodecContext *ac = NULL;
AVStream *as = NULL;

queue<Mat *> video_queue;
mutex video_mux;

queue<char *> audio_queue;
mutex audio_mux;

long long int time_start = 0;


void video() {
    AVPacket *pkt = av_packet_alloc();
    while (isRunning) {
        if (packs.size() > 100) {
            av_usleep(1);
            continue;
        }

        if (video_queue.empty()) {
            av_usleep(1);
            continue;
        }

        video_mux.lock();
        Mat *mat = video_queue.front();
        video_queue.pop();
        video_mux.unlock();


        ///rgb to yuv
        uint8_t *indata[AV_NUM_DATA_POINTERS] = {0};
        indata[0] = mat->data;
        int insize[AV_NUM_DATA_POINTERS] = {0};
        insize[0] = mat->cols * mat->elemSize();
        sws_scale(vsc,
                  indata, insize, 0, mat->rows, //源数据
                  yuv_frame->data, yuv_frame->linesize);

        ///h264编码
        yuv_frame->pts = av_gettime() - time_start;
        avcodec_send_frame(vc, yuv_frame);
        avcodec_receive_packet(vc, pkt);

        mat->release();

        pkt->pts = av_rescale_q(pkt->pts, vc->time_base, vs->time_base);
        pkt->dts = av_rescale_q(pkt->dts, vc->time_base, vs->time_base);
        pkt->duration = av_rescale_q(pkt->duration, vc->time_base, vs->time_base);
        pkt->stream_index = vs->index;

        //推流
        AVPacket *video_pack = av_packet_clone(pkt);

        packs_mux.lock();
        packs.push(video_pack);
        packs_mux.unlock();

    }
    isExit[0] = true;
}

void audio() {

    AVPacket *pkt = av_packet_alloc();
    while (isRunning) {

        if (packs.size() > 100) {
            av_usleep(1);
            continue;
        }

        if (audio_queue.empty()) {
            av_usleep(1);
            continue;
        }

        char *audio_data = nullptr;
        audio_mux.lock();
        audio_data = audio_queue.front();
        audio_queue.pop();
        audio_mux.unlock();

        const uint8_t *indata[AV_NUM_DATA_POINTERS] = {0};
        indata[0] = (uint8_t *) audio_data;
        swr_convert(asc,
                    pcm_frame->data, pcm_frame->nb_samples,
                    indata, pcm_frame->nb_samples);
        pcm_frame->pts = av_gettime() - time_start;
        free(audio_data);//clean audio_data's memory

        avcodec_send_frame(ac, pcm_frame);
        avcodec_receive_packet(ac, pkt);

        pkt->pts = av_rescale_q(pkt->pts, ac->time_base, as->time_base);
        pkt->dts = av_rescale_q(pkt->dts, ac->time_base, as->time_base);
        pkt->duration = av_rescale_q(pkt->duration, ac->time_base, as->time_base);
        pkt->stream_index = as->index;

        AVPacket *audio_pack = av_packet_clone(pkt);
        packs_mux.lock();
        packs.push(audio_pack);
        packs_mux.unlock();
    }
    isExit[1] = true;


}

void push_thread() {
    while (isRunning) {
        packs_mux.lock();
        if (packs.empty()) {
            packs_mux.unlock();
            av_usleep(1);
            continue;
        }
        AVPacket *pkt = packs.front();
        packs.pop();
        LOGE("%d", pkt->stream_index)
        packs_mux.unlock();
        int re = av_interleaved_write_frame(ic, pkt);
        if (re == 0) {
            LOGE("#");
        }
        av_packet_free(&pkt);
    }
    isExit[2] = true;
}

void init(int width, int height, const char *string1) {
    //set isExit all false
    isRunning = true;
    for (int i = 0; i < 3; ++i) {
        isExit[i] = false;
    }

    avcodec_register_all();
    av_register_all();
    avformat_network_init();
    avformat_alloc_output_context2(&ic, 0, "flv", outUrl);

    vsc = sws_getCachedContext(vsc,
                               width, height,
                               AV_PIX_FMT_RGBA,     //源宽、高、像素格式
                               width, height,
                               AV_PIX_FMT_YUV420P,//目标宽、高、像素格式
                               SWS_BICUBIC,  // 尺寸变化使用算法
                               0, 0, 0
    );
    yuv_frame = av_frame_alloc();
    yuv_frame->format = AV_PIX_FMT_YUV420P;
    yuv_frame->width = width;
    yuv_frame->height = height;
    yuv_frame->pts = 0;
    av_frame_get_buffer(yuv_frame, 32);
    AVCodec *video_codec = avcodec_find_encoder(AV_CODEC_ID_H264);
    vc = avcodec_alloc_context3(video_codec);
    vc->flags |= AV_CODEC_FLAG_GLOBAL_HEADER; //全局参数
    vc->codec_id = video_codec->id;
    vc->thread_count = 8;
    vc->bit_rate = 200 * 1024 * 8;
    vc->width = width;
    vc->height = height;
    vc->time_base = {1, 1000000};
    vc->framerate = {33, 1};
    vc->gop_size = 25;
    vc->max_b_frames = 1;
    vc->pix_fmt = AV_PIX_FMT_YUV420P;
    avcodec_open2(vc, video_codec, 0);


    asc = swr_alloc_set_opts(asc,
                             av_get_default_channel_layout(2),
                             AV_SAMPLE_FMT_FLTP,
                             44100,
                             av_get_default_channel_layout(2),
                             AV_SAMPLE_FMT_S16,
                             44100,
                             0,
                             nullptr);
    swr_init(asc);
    pcm_frame = av_frame_alloc();
    pcm_frame->format = AV_SAMPLE_FMT_FLTP;
    pcm_frame->channels = 2;
    pcm_frame->channel_layout = av_get_default_channel_layout(2);
    pcm_frame->nb_samples = 1024;//一帧音频单通道的采样数量
    pcm_frame->pts = 0;
    av_frame_get_buffer(pcm_frame, 0);
    AVCodec *audio_codec = avcodec_find_encoder(AV_CODEC_ID_AAC);
    ac = avcodec_alloc_context3(audio_codec);
    ac->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;
    ac->codec_id = audio_codec->id;
    ac->sample_fmt = AV_SAMPLE_FMT_FLTP;
    ac->sample_rate = 44100;
    ac->channel_layout = av_get_default_channel_layout(2);
    ac->channels = 2;
    ac->thread_count = 8;
    ac->bit_rate = 40000;
    ac->time_base = {1, 1000000};
    avcodec_open2(ac, audio_codec, nullptr);

    as = avformat_new_stream(ic, NULL);
    as->codecpar->codec_tag = 0;
    avcodec_parameters_from_context(as->codecpar, ac);

    vs = avformat_new_stream(ic, NULL);
    vs->codecpar->codec_tag = 0;
    avcodec_parameters_from_context(vs->codecpar, vc);

    int re = avio_open(&ic->pb, outUrl, AVIO_FLAG_WRITE);
    if (re != 0) {
        LOGE("avio_open failed");
        return;
    }
    LOGE("avio_open success")
    avformat_write_header(ic, NULL);
    time_start = av_gettime();
}

void pushVideo(jlong mat_addr) {
    Mat *mat = new Mat();
    ((Mat *) mat_addr)->copyTo(*mat);
    //rotate 90 degree
    rotate(*mat, *mat, ROTATE_90_CLOCKWISE);
    while (video_queue.size() > 100) {
        av_usleep(1);
    }
    video_mux.lock();
    video_queue.push(mat);
    video_mux.unlock();
}

void pushAudio(jbyte *audio_data, jint len) {
    char *audio = new char[len];
    memcpy(audio, audio_data, len);
    while (audio_queue.size() > 100 && isRunning) {
        av_usleep(1);
    }
    audio_mux.lock();
    audio_queue.push(audio);
    audio_mux.unlock();
}

void startPush() {
    isRunning = true;
    thread vt(video);
    thread at(audio);
    thread p(push_thread);
    vt.detach();
    at.detach();
    p.detach();
}

void stopPush() {
    isRunning = false;
    while (!isExit[0] || !isExit[1] || !isExit[2]) {
        av_usleep(1);
    }
    LOGE("stopPush")
    if (ic) {
        av_write_trailer(ic);
        avio_close(ic->pb);
        avformat_free_context(ic);
        ic = NULL;
    }
    LOGE("ic free")
    if (vc) {
        avcodec_close(vc);
        avcodec_free_context(&vc);
        vc = NULL;
    }
    LOGE("vc free")
    if (ac) {
        avcodec_close(ac);
        avcodec_free_context(&ac);
        ac = NULL;
    }
    LOGE("ac free")
    if (yuv_frame) {
        av_frame_free(&yuv_frame);
        yuv_frame = NULL;
    }
    LOGE("yuv_frame free")
    if (pcm_frame) {
        av_frame_free(&pcm_frame);
        pcm_frame = NULL;
    }
    LOGE("pcm_frame free")

    if (vsc) {
        sws_freeContext(vsc);
        vsc = NULL;
    }
    LOGE("vsc free")
    if (asc) {
        swr_free(&asc);
        asc = NULL;
    }
    LOGE("asc free")
    while (!packs.empty()) {
        AVPacket *pkt = packs.front();
        av_packet_free(&pkt);
        packs.pop();
    }
    LOGE("packs free")
    while (!audio_queue.empty()) {
        char *audio_data = audio_queue.front();
        free(audio_data);
        audio_queue.pop();
    }
    LOGE("audio_queue free")
    while (!video_queue.empty()) {
        Mat *mat = video_queue.front();
        mat->release();
        video_queue.pop();
    }
    LOGE("video_queue free")

    LOGE("stopPush");


}


extern "C"
JNIEXPORT void JNICALL
Java_com_example_zchan_1rtmp_LiveImp_pushVideo(JNIEnv *env, jclass clazz, jlong mat_addr) {
    pushVideo(mat_addr);
}
extern "C"
JNIEXPORT void JNICALL
Java_com_example_zchan_1rtmp_LiveImp_pushAudio(JNIEnv *env, jclass clazz, jbyteArray data,
                                               jint len) {
    jbyte *audio_data = env->GetByteArrayElements(data, NULL);
    pushAudio(audio_data, len);
    env->ReleaseByteArrayElements(data, audio_data, 0);
}

extern "C"
JNIEXPORT void JNICALL
Java_com_example_zchan_1rtmp_LiveImp_init(JNIEnv *env, jclass clazz, jint width, jint height) {
    init(width, height);
}
extern "C"
JNIEXPORT void JNICALL
Java_com_example_zchan_1rtmp_LiveImp_stopPush(JNIEnv *env, jclass clazz) {
    stopPush();
}
extern "C"
JNIEXPORT void JNICALL
Java_com_example_zchan_1rtmp_LiveImp_startPush(JNIEnv *env, jclass clazz) {
    startPush();
}